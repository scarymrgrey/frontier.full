17:48:57.159 [main] DEBUG uk.ac.imperial.lsds.seep.GLOBALS - Loading GLOBALS...
17:48:57.162 [main] INFO  uk.ac.imperial.lsds.seep.GLOBALS - Loaded global properties={replicatedSinksHashRouting=backpressure, reprocessNonLocals=false, rateLimitConnections=false, chainLength=1, monitorInterval=5, recordImages=false, costThreshold=40.0, routeRecomputeIntervalSec=10, minimumNodesAvailable=10, ctrlSocketBufSize=2048, enableFrontierRouting=true, srcOutputQueueTimestamps=false, routingCtrlDelay=1000, ackEmitInterval=3000, synchronousOutput=true, enableAutomaticScaleOut=true, monitorManagerPort=5555, coreMainAddr=172.16.1.2, multiHopReplayOptimization=true, disableBackup=true, queryType=fdr, INIT=true, packetSize=16000, socketBufferSize=16384, sinkScaleFactor=1, extraProps=../extraConfig.properties, reorderImages=false, costExponent=2.0, srcMaxBufferMB=20, resizeImages=false, fctrlEmitInterval=1000, minimumTimeBetweenSplit=6, maxTotalQueueSizeTuples=100, fanin=2, trySendAlternativesTimeout=3000, enableLatencyBreakdown=false, socketConnectTimeout=10000, reliability=exactlyOnce, useCoreAddr=, TTT=FALSE, tupleSize=10, maxSrcTotalQueueSizeTuples=1, enableHardReplay=true, scheduledPauses=false, bestEffortAcks=true, numTuples=86, downstreamsUnroutableTimeout=3000, trySendTimeout=500, frameRate=1, batchLimit=1, enableFailureCtrlWatchdog=true, reportMaxSrcTotalQueueSizeTuples=false, warmUpTuples=0, abortOnNodePoolEmpty=true, enableTupleTracking=true, repoDir=/home/scary/Sources/frontier, sendIndefinitely=true, eftMechanismEnabled=true, net-routing=OLSRETX, piggybackControlTraffic=true, eagerPurgeOpQueue=false, dataSocket=40000, baseId=50, enableSinkDisplay=false, abortSessionTimeoutSec=300, numMaxAlerts=2, barrierTimeout=0, controlSocket=50000, fileWithCpuU=OUT, ownPort=3500, optimizeReplay=true, netAwareDispatcher=true, enableGUI=false, sources=1, maxLatencyAllowed=250, reconnectBackoff=100, separateControlNet=false, multicoreSupport=false, tupleSizeChars=500, initialPause=1000, rateLimitSrc=false, enableBatchRetransmitTimeouts=false, stateChunkSize=500000, sourceShutdownPause=300, ackWorkerActive=false , replicationFactor=1, sendDummyUpDownControlTraffic=false, sinks=1, readyQueueLength=10, retransmitTimeout=3000, sendDummyDownUpControlTraffic=false, skewLimit=0, boundReadyQueue=false, scaleOutSinks=true, fctrlWorkerActive=true, cpuUThreshold=50, autoReconnectChannel=true, mainPort=3500, boundFrontierRoutingQueues=true, blindSocket=60000, resourcesInJar=false, enableUpstreamRoutingControl=false, failureCtrlTimeout=3000, testFramesDir=images0.5, periodicFctrlsOnly=true, ftDiskMode=true, defaultProcessingDelay=0, mergeFailureAndRoutingCtrl=true, parallelRecovery=true, inputQueueLength=100, restrictRetransmitConstrained=false, ignoreQueueLengths=false, disableBackpressureETX=false, requirePositiveAggregates=false, piAdHocDeployment=true, checkpointMode=light-state, frontierRouting=backpressure, enableDownstreamsUnroutable=false, sendDummyFailureControlTraffic=false, noBufferSave=false, mainAddr=127.0.0.1}
17:48:57.162 [main] DEBUG uk.ac.imperial.lsds.seep.GLOBALS - Loading GLOBALS...Done
17:48:57.162 [main] INFO  uk.ac.imperial.lsds.seep.GLOBALS - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
17:48:57.162 [main] INFO  uk.ac.imperial.lsds.seep.Main - Bind address=/127.0.0.1
17:48:57.162 [main] INFO  uk.ac.imperial.lsds.seep.Main - globalProps={replicatedSinksHashRouting=backpressure, reprocessNonLocals=false, rateLimitConnections=false, chainLength=1, monitorInterval=5, recordImages=false, costThreshold=40.0, routeRecomputeIntervalSec=10, minimumNodesAvailable=10, ctrlSocketBufSize=2048, enableFrontierRouting=true, srcOutputQueueTimestamps=false, routingCtrlDelay=1000, ackEmitInterval=3000, synchronousOutput=true, enableAutomaticScaleOut=true, monitorManagerPort=5555, coreMainAddr=172.16.1.2, multiHopReplayOptimization=true, disableBackup=true, queryType=fdr, INIT=true, packetSize=16000, socketBufferSize=16384, sinkScaleFactor=1, extraProps=../extraConfig.properties, reorderImages=false, costExponent=2.0, srcMaxBufferMB=20, resizeImages=false, fctrlEmitInterval=1000, minimumTimeBetweenSplit=6, maxTotalQueueSizeTuples=100, fanin=2, trySendAlternativesTimeout=3000, enableLatencyBreakdown=false, socketConnectTimeout=10000, reliability=exactlyOnce, useCoreAddr=, TTT=FALSE, tupleSize=10, maxSrcTotalQueueSizeTuples=1, enableHardReplay=true, scheduledPauses=false, bestEffortAcks=true, numTuples=86, downstreamsUnroutableTimeout=3000, trySendTimeout=500, frameRate=1, batchLimit=1, enableFailureCtrlWatchdog=true, reportMaxSrcTotalQueueSizeTuples=false, warmUpTuples=0, abortOnNodePoolEmpty=true, enableTupleTracking=true, repoDir=/home/scary/Sources/frontier, sendIndefinitely=true, eftMechanismEnabled=true, net-routing=OLSRETX, piggybackControlTraffic=true, eagerPurgeOpQueue=false, dataSocket=40000, baseId=50, enableSinkDisplay=false, abortSessionTimeoutSec=300, numMaxAlerts=2, barrierTimeout=0, controlSocket=50000, fileWithCpuU=OUT, ownPort=3500, optimizeReplay=true, netAwareDispatcher=true, enableGUI=false, sources=1, maxLatencyAllowed=250, reconnectBackoff=100, separateControlNet=false, multicoreSupport=false, tupleSizeChars=500, initialPause=1000, rateLimitSrc=false, enableBatchRetransmitTimeouts=false, stateChunkSize=500000, sourceShutdownPause=300, ackWorkerActive=false , replicationFactor=1, sendDummyUpDownControlTraffic=false, sinks=1, readyQueueLength=10, retransmitTimeout=3000, sendDummyDownUpControlTraffic=false, skewLimit=0, boundReadyQueue=false, scaleOutSinks=true, fctrlWorkerActive=true, cpuUThreshold=50, autoReconnectChannel=true, mainPort=3500, boundFrontierRoutingQueues=true, blindSocket=60000, resourcesInJar=false, enableUpstreamRoutingControl=false, failureCtrlTimeout=3000, testFramesDir=images0.5, periodicFctrlsOnly=true, ftDiskMode=true, defaultProcessingDelay=0, mergeFailureAndRoutingCtrl=true, parallelRecovery=true, inputQueueLength=100, restrictRetransmitConstrained=false, ignoreQueueLengths=false, disableBackpressureETX=false, requirePositiveAggregates=false, piAdHocDeployment=true, checkpointMode=light-state, frontierRouting=backpressure, enableDownstreamsUnroutable=false, sendDummyFailureControlTraffic=false, noBufferSave=false, mainAddr=127.0.0.1}
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - Interface wlo1 wlo1
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - New preferred interface wlo1 with match index -1
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - Ignoring IPv6 address /fe80:0:0:0:6de1:aed4:21b6:1937%wlo1
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - New preferred address /192.168.1.194
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - Interface lo lo
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - New preferred interface lo with match index 2
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - Ignoring IPv6 address /0:0:0:0:0:0:0:1%lo
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - New preferred address /127.0.0.1
17:48:57.164 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - Choosing wireless net data/control ip=/127.0.0.1
17:48:57.169 [main] INFO  uk.ac.imperial.lsds.seep.Main - Initializing Node Manager...
17:48:57.172 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - Waiting for incoming requests on port: 3502
17:48:57.173 [main] INFO  u.a.i.l.s.c.NodeManagerCommunication - --> Boot Info: bootstrap 127.0.0.1 127.0.0.1 3502
 to: /127.0.0.1 on: 3500
17:49:02.062 [main] DEBUG u.a.i.l.s.infrastructure.NodeManager - Tokens received: CODE
17:49:02.062 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - -> CODE Command
17:49:02.062 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - -> Waiting for receiving the CODE...
17:49:02.062 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - -> CODE received completely
17:49:02.062 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - -> Loading CODE from: /home/scary/Sources/frontier/seep-system/examples/stateless-simple-query/3502query.jar
Loading into class loader: file:/home/scary/Sources/frontier/seep-system/examples/stateless-simple-query/3502query.jar
17:49:02.093 [main] DEBUG u.a.i.l.s.infrastructure.NodeManager - -> Received Unknown Class -> java.util.ArrayList <- Using custom class loader to resolve it
17:49:02.155 [main] DEBUG u.a.i.l.s.infrastructure.NodeManager - -> Received Unknown Class -> uk.ac.imperial.lsds.seep.operator.Operator <- Using custom class loader to resolve it
17:49:02.173 [main] ERROR u.a.i.l.s.i.d.RuntimeClassLoader - This URL: file:/home/scary/Sources/frontier/seep-system/examples/stateless-simple-query/3502query.jar
17:49:02.173 [main] ERROR u.a.i.l.s.i.d.RuntimeClassLoader - When trying to load: [Ljava.lang.Integer;
17:49:02.180 [main] DEBUG u.a.i.l.s.infrastructure.NodeManager - -> OPERATOR resolved, OP-ID: 1
17:49:02.181 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - -> Node Monitor running for operatorId=1
17:49:02.188 [main] INFO  u.a.i.l.s.p.StatelessProcessingUnit - -> Instantiating Operator...
17:49:02.191 [main] INFO  u.a.i.l.s.processingunit.Dispatcher - canRetransmitConstrained=true
17:49:02.192 [main] INFO  u.a.i.l.s.processingunit.Dispatcher - limitUnacked=false,maxUnacked=99


17:49:02.193 [main] DEBUG u.a.i.l.s.p.StatelessProcessingUnit - Operator: Operator [operatorId=1, opContext= @node: Node [ip=/127.0.0.1, controlIp=/127.0.0.1, masterCommsIp=/127.0.0.1, port=3502]inC: 50001inD: 40001 down: [Id: -2node: Node [ip=/127.0.0.1, controlIp=/127.0.0.1, masterCommsIp=/127.0.0.1, port=3503]inC: 49998inD: 39998] up: [Id: -1node: Node [ip=/127.0.0.1, controlIp=/127.0.0.1, masterCommsIp=/127.0.0.1, port=3501]inC: 49999inD: 39999]]
17:49:02.193 [main] INFO  u.a.i.l.s.p.StatelessProcessingUnit - -> Instantiating Operator...DONE
17:49:02.204 [main] INFO  u.a.i.l.s.p.StatelessProcessingUnit - -> Setting operator ready
17:49:02.204 [main] INFO  u.a.i.lsds.seep.runtimeengine.CoreRE - -> All operators in this unit are ready. Initializing communications...
17:49:02.222 [main] INFO  u.a.i.l.s.r.OutputQueueWorker - OutputQueue worker merging failure and routing ctrl? false
17:49:02.223 [main] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Upstream: -1 with this mode: ONE_AT_A_TIME
17:49:02.223 [main] DEBUG u.a.i.l.s.r.DataStructureAdapter - -> Setting up a unique InputDataIngestionMode
17:49:02.223 [main] INFO  u.a.i.l.s.r.OutOfOrderFairInputQueue - Setting max input queue size to:100
17:49:02.223 [main] INFO  u.a.i.l.s.r.OutOfOrderFairInputQueue - Input queue reliability: bestEffort=false,optimizeReplay=true
17:49:02.224 [main] DEBUG u.a.i.l.s.r.DataStructureAdapter - -> Ingest with InputQueue from -1
17:49:02.224 [main] INFO  u.a.i.lsds.seep.runtimeengine.CoreRE - Creating ctrlQueue for up op: -1
17:49:02.224 [main] INFO  u.a.i.lsds.seep.runtimeengine.CoreRE - Control queues: {-1=[]}
17:49:02.225 [main] INFO  u.a.i.l.s.comm.IncomingDataHandler -  -> ctrl queues = {-1=[]}
17:49:02.227 [dataHandlerT] INFO  u.a.i.l.s.comm.IncomingDataHandler - -> IncomingDataHandler listening in port: 40001
17:49:02.227 [dataHandlerT] INFO  u.a.i.l.s.comm.IncomingDataHandler - idh socket receiver buffer size = 16384
17:49:02.233 [dataHandlerT] INFO  u.a.i.l.s.comm.IncomingDataHandler - -> Creating worker for upstream: -1
17:49:02.233 [dataHandlerT] INFO  u.a.i.l.s.comm.IncomingDataHandler - -> ctrl queue:[]
17:49:02.233 [dataHandlerT] INFO  u.a.i.l.s.comm.IncomingDataHandler - -> index:0, upOpIds=[-1],indexes=[0]
17:49:02.233 [dataHandlerT] WARN  u.a.i.l.s.comm.IncomingDataHandler - Received incoming data conn but pu ctxt not created yet. Closing.
17:49:02.241 [main] DEBUG u.a.i.l.s.infrastructure.NodeManager - Tokens received: SET-RUNTIME
17:49:02.242 [main] INFO  u.a.i.l.s.infrastructure.NodeManager - -> SET-RUNTIME Command
17:49:02.242 [main] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - -> Configuring remote connections...
17:49:02.242 [main] DEBUG u.a.i.l.s.processingunit.PUContext - -> configuring downstream of -2
17:49:02.242 [main] DEBUG u.a.i.l.s.processingunit.PUContext - -> Trying remote deferred downstream conn to: /127.0.0.1/39998
17:49:02.245 [main] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Starting deferred init to /127.0.0.1
17:49:02.245 [main] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Skipping deferred init to /127.0.0.1
17:49:02.245 [main] DEBUG u.a.i.l.s.processingunit.PUContext - -> New remote downstream (SYNC) conn to OP: 
17:49:02.245 [main] DEBUG u.a.i.l.s.processingunit.PUContext - -> Trying remote deferred upstream conn to: /127.0.0.1/49999
17:49:02.246 [main] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Starting deferred init to /127.0.0.1
17:49:02.246 [main] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Skipping deferred init to non downstream data conn /127.0.0.1
17:49:02.246 [main] DEBUG u.a.i.l.s.processingunit.PUContext - -> PUContext. New remote upstream (sync) conn to OP: -1
17:49:02.246 [main] WARN  u.a.i.l.s.p.StatelessProcessingUnit - Using hash routing since no replication.
17:49:02.246 [main] INFO  u.a.i.l.s.p.StatelessProcessingUnit - Using hash routing.
17:49:02.247 [main] INFO  u.a.i.l.s.processingunit.Dispatcher - Set dispatcher output queues and started dispatcher workers.
17:49:02.248 [main] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - -> CONFIGURING SYSTEM WITH A SYNCHRONOUS OUTPUT
17:49:02.248 [main] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - -> SYSTEM CONFIGURED FOR NO MULTICORE
17:49:02.248 [dataConsumerT] INFO  u.a.i.l.s.runtimeengine.DataConsumer - 1 input data ingestion mode.
17:49:02.248 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Reopening downstream data socket
17:49:02.248 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Trying a deferred init of data channel to /127.0.0.1
17:49:02.248 [dataConsumerT] INFO  u.a.i.l.s.runtimeengine.DataConsumer - Pulling from input queue
17:49:02.248 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Successfully connected data channel to /127.0.0.1
17:49:02.248 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Socket send buffer size= 1313280
17:49:02.248 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Socket set send buffer size= 16384
17:49:02.248 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 connected to downstream: -2
17:49:02.248 [DispatcherWorker--2] INFO  u.a.i.l.s.processingunit.Dispatcher - Dispatcher worker initial reconnect complete.
17:49:02.254 [main] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - -> Node -1556466654 instantiated
% ConfigureUpstreamIndex
% current backupIdx: -1 changes to: 0
17:49:02.255 [main] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - -> The new Upstream backup INDEX is: 0
17:49:02.255 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:02.255 [main] WARN  u.a.i.lsds.seep.runtimeengine.CoreRE - Using hash routing since no replication.
17:49:02.255 [main] INFO  u.a.i.lsds.seep.runtimeengine.CoreRE - Starting OLSRETX net rate monitor.
17:49:02.255 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:02.256 [chw-/127.0.0.1-T-0] ERROR u.a.i.l.s.comm.ControlHandlerWorker - -> ControlHandlerWorker. IO Error Buffer underflow.
17:49:02.256 [main] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Net rate monitor using up op id to addr mapping: {-1=localhost}
17:49:02.256 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::,upOp=-1::
17:49:02.256 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 1 ms
17:49:02.256 [Thread-1] WARN  u.a.i.l.s.r.ControlDispatcherWorker - Dropping control msg as control socket is null.
com.esotericsoftware.kryo.KryoException: Buffer underflow.17:49:02.256 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::,downstreamsRoutable=true

17:49:02.256 [Thread-1] WARN  u.a.i.l.s.r.ControlDispatcherWorker - Sending control tuple to -1 failed in 0 ms
	at com.esotericsoftware.kryo.io.Input.require(Input.java:181)
	at com.esotericsoftware.kryo.io.Input.readVarInt(Input.java:355)
	at com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:794)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:655)
	at uk.ac.imperial.lsds.seep.comm.ControlHandlerWorker.socketRead(ControlHandlerWorker.java:189)
	at uk.ac.imperial.lsds.seep.comm.ControlHandlerWorker.run(ControlHandlerWorker.java:137)
	at java.lang.Thread.run(Thread.java:748)
17:49:02.256 [main] INFO  u.a.i.l.s.processingunit.Dispatcher - Started dispatcher main.
17:49:02.256 [main] INFO  u.a.i.lsds.seep.runtimeengine.CoreRE - -> Node -1556466654 comm initialized
17:49:02.262 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Read routes: []
17:49:02.262 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Parsing OLSRETX routes
17:49:02.263 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Checking routes against upOpIds: {-1=localhost}
17:49:02.263 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Up op costs: {}
17:49:02.273 [dataHandlerT] INFO  u.a.i.l.s.comm.IncomingDataHandler - -> Creating worker for upstream: -1
17:49:02.273 [dataHandlerT] INFO  u.a.i.l.s.comm.IncomingDataHandler - -> ctrl queue:[]
17:49:02.273 [dataHandlerT] INFO  u.a.i.l.s.comm.IncomingDataHandler - -> index:0, upOpIds=[-1],indexes=[0]
17:49:02.276 [dataHandlerT] INFO  u.a.i.l.s.c.IncomingDataHandlerWorker - Created icdhw with ctrlQueue = []
17:49:02.276 [dataHandlerT] ERROR u.a.i.l.s.r.SynchronousCommunicationChannel - Set socket snd buf size failed, requested=2048, send=2304
17:49:02.276 [idhjw-/127.0.0.1-T-0] INFO  u.a.i.l.s.c.IncomingDataHandlerWorker - -> Unique data adapter in this node: uk.ac.imperial.lsds.seep.runtimeengine.OutOfOrderFairInputQueue@2bef466e
17:49:03.256 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:03.257 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:03.257 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::,upOp=-1::
17:49:03.257 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 1 ms
17:49:03.258 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::,downstreamsRoutable=true
17:49:03.261 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=15 in 2 ms (+sync=3 ms)
17:49:04.259 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:04.259 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:04.259 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::,upOp=-1::
17:49:04.259 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 0 ms
17:49:04.259 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::,downstreamsRoutable=true
17:49:04.259 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=15 in 0 ms (+sync=0 ms)
17:49:04.264 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Read routes: []
17:49:04.265 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Parsing OLSRETX routes
17:49:04.266 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Checking routes against upOpIds: {-1=localhost}
17:49:04.266 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Up op costs: {}
17:49:04.282 [dataConsumerT] DEBUG u.a.i.l.s.r.OutputQueueWorker - Setting data with ts=1593812944274
17:49:04.282 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 exchanged ctrlData for -2
17:49:04.282 [Thread-2] INFO  u.a.i.l.s.r.OutputQueueWorker - t=1593812944282, oq.sync 1 sending ts=1593812944274 for -2, current latency=8, oq latency=2
17:49:04.282 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - No coalescing for -2: 0.0
17:49:04.282 [Thread-2] ERROR u.a.i.l.s.r.OutputQueueWorker - Writing batch to -2 failed, ts=1593812944274, com.esotericsoftware.kryo.KryoException: java.net.SocketException: Socket closed
17:49:04.283 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 sent ctrlData for -2, success=false
17:49:04.283 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Reopening downstream data socket
17:49:04.283 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Existing downstream data socket not null: /127.0.0.1
com.esotericsoftware.kryo.KryoException: java.net.SocketException: Socket closed
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:165)
	at com.esotericsoftware.kryo.io.Output.close(Output.java:173)
	at uk.ac.imperial.lsds.seep.runtimeengine.SynchronousCommunicationChannel.reopenDownstreamDataSocket(SynchronousCommunicationChannel.java:193)
	at uk.ac.imperial.lsds.seep.runtimeengine.OutputQueueWorker$2.run(OutputQueueWorker.java:170)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketException: Socket closed
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:155)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:163)
	... 4 more
17:49:04.283 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Successfully connected data channel to /127.0.0.1
17:49:04.283 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Socket send buffer size= 1313280
17:49:04.283 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Socket set send buffer size= 16384
17:49:04.283 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 connected to downstream: -2
17:49:05.260 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:05.260 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:05.272 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Read control tuple in 987 ms,txnDelay=0
17:49:05.272 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Processed control tuple in 0 ms
17:49:05.279 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::,upOp=-1::[1593812944274:1593812944275)
17:49:05.279 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 20 ms
17:49:05.279 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::,downstreamsRoutable=true
17:49:05.280 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=44 in 0 ms (+sync=0 ms)
17:49:06.273 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Read control tuple in 1000 ms,txnDelay=1
17:49:06.275 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Processed control tuple in 2 ms
17:49:06.276 [dataConsumerT] DEBUG u.a.i.l.s.r.OutputQueueWorker - Setting data with ts=1593812946274
17:49:06.276 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Read routes: []
17:49:06.276 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 exchanged ctrlData for -2
17:49:06.276 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Parsing OLSRETX routes
17:49:06.276 [Thread-2] INFO  u.a.i.l.s.r.OutputQueueWorker - t=1593812946276, oq.sync 1 sending ts=1593812946274 for -2, current latency=2, oq latency=0
17:49:06.276 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Checking routes against upOpIds: {-1=localhost}
17:49:06.276 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - No coalescing for -2: 0.0
17:49:06.276 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Up op costs: {}
17:49:06.276 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 sent ctrlData for -2, success=true
17:49:06.280 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:06.280 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:06.280 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::,upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275)
17:49:06.280 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 0 ms
17:49:06.281 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::,downstreamsRoutable=true
17:49:06.281 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=106 in 0 ms (+sync=0 ms)
17:49:07.277 [dataConsumerT] DEBUG u.a.i.l.s.r.OutputQueueWorker - Setting data with ts=1593812947275
17:49:07.278 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 exchanged ctrlData for -2
17:49:07.278 [Thread-2] INFO  u.a.i.l.s.r.OutputQueueWorker - t=1593812947278, oq.sync 1 sending ts=1593812947275 for -2, current latency=3, oq latency=1
17:49:07.278 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - No coalescing for -2: 0.0
17:49:07.279 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 sent ctrlData for -2, success=true
17:49:07.281 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:07.281 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:07.281 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::,upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276)
17:49:07.281 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 0 ms
17:49:07.281 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::,downstreamsRoutable=true
17:49:07.282 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=136 in 1 ms (+sync=1 ms)
17:49:07.292 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Read control tuple in 1016 ms,txnDelay=3
17:49:07.292 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Processed control tuple in 0 ms
17:49:08.278 [dataConsumerT] DEBUG u.a.i.l.s.r.OutputQueueWorker - Setting data with ts=1593812948276
17:49:08.279 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 exchanged ctrlData for -2
17:49:08.279 [Thread-2] INFO  u.a.i.l.s.r.OutputQueueWorker - t=1593812948279, oq.sync 1 sending ts=1593812948276 for -2, current latency=3, oq latency=1
17:49:08.279 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - No coalescing for -2: 0.0
17:49:08.279 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 sent ctrlData for -2, success=true
17:49:08.282 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:08.282 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:08.285 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::[1593812946274:1593812946275),upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277)
17:49:08.287 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 5 ms
17:49:08.287 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Read routes: []
17:49:08.287 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Parsing OLSRETX routes
17:49:08.287 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=166 in 0 ms (+sync=0 ms)
17:49:08.287 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Checking routes against upOpIds: {-1=localhost}
17:49:08.287 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Up op costs: {}
17:49:08.287 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::[1593812946274:1593812946275),downstreamsRoutable=true
17:49:08.293 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Read control tuple in 1001 ms,txnDelay=0
17:49:08.293 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Processed control tuple in 0 ms
17:49:09.279 [dataConsumerT] DEBUG u.a.i.l.s.r.OutputQueueWorker - Setting data with ts=1593812949277
17:49:09.280 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 exchanged ctrlData for -2
17:49:09.280 [Thread-2] INFO  u.a.i.l.s.r.OutputQueueWorker - t=1593812949280, oq.sync 1 sending ts=1593812949277 for -2, current latency=3, oq latency=1
17:49:09.280 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - No coalescing for -2: 0.0
17:49:09.280 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 sent ctrlData for -2, success=true
17:49:09.288 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:09.288 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:09.291 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278)
17:49:09.292 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 4 ms
17:49:09.292 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=196 in 0 ms (+sync=0 ms)
17:49:09.293 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),downstreamsRoutable=true
17:49:09.294 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Read control tuple in 1001 ms,txnDelay=0
17:49:09.295 [chw-/127.0.0.1-T-1] DEBUG u.a.i.l.s.comm.ControlHandlerWorker - Processed control tuple in 1 ms
17:49:09.665 [chw-/127.0.0.1-T-1] ERROR u.a.i.l.s.comm.ControlHandlerWorker - -> ControlHandlerWorker. IO Error Buffer underflow.
com.esotericsoftware.kryo.KryoException: Buffer underflow.
	at com.esotericsoftware.kryo.io.Input.require(Input.java:181)
	at com.esotericsoftware.kryo.io.Input.readVarInt(Input.java:355)
	at com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:794)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:655)
	at uk.ac.imperial.lsds.seep.comm.ControlHandlerWorker.socketRead(ControlHandlerWorker.java:189)
	at uk.ac.imperial.lsds.seep.comm.ControlHandlerWorker.run(ControlHandlerWorker.java:137)
	at java.lang.Thread.run(Thread.java:748)
17:49:10.281 [dataConsumerT] DEBUG u.a.i.l.s.r.OutputQueueWorker - Setting data with ts=1593812950278
17:49:10.282 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 exchanged ctrlData for -2
17:49:10.282 [Thread-2] INFO  u.a.i.l.s.r.OutputQueueWorker - t=1593812950282, oq.sync 1 sending ts=1593812950278 for -2, current latency=4, oq latency=1
17:49:10.282 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - No coalescing for -2: 0.0
17:49:10.283 [Thread-2] ERROR u.a.i.l.s.r.OutputQueueWorker - Writing batch to -2 failed, ts=1593812950278, com.esotericsoftware.kryo.KryoException: java.net.SocketException: Socket closed
17:49:10.283 [Thread-2] DEBUG u.a.i.l.s.r.OutputQueueWorker - Op 1 sent ctrlData for -2, success=false
17:49:10.283 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Reopening downstream data socket
17:49:10.283 [Thread-2] INFO  u.a.i.l.s.r.SynchronousCommunicationChannel - Existing downstream data socket not null: /127.0.0.1
com.esotericsoftware.kryo.KryoException: java.net.SocketException: Socket closed
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:165)
	at com.esotericsoftware.kryo.io.Output.close(Output.java:173)
	at uk.ac.imperial.lsds.seep.runtimeengine.SynchronousCommunicationChannel.reopenDownstreamDataSocket(SynchronousCommunicationChannel.java:193)
	at uk.ac.imperial.lsds.seep.runtimeengine.OutputQueueWorker$2.run(OutputQueueWorker.java:170)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketException: Socket closed
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:155)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:163)
	... 4 more
17:49:10.286 [Thread-2] ERROR u.a.i.l.s.r.SynchronousCommunicationChannel - Data connection 0 to /127.0.0.1 failed: java.net.ConnectException: Connection refused (Connection refused)
17:49:10.293 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Read routes: []
17:49:10.293 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Parsing OLSRETX routes
17:49:10.293 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Checking routes against upOpIds: {-1=localhost}
17:49:10.293 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Up op costs: {}
17:49:10.293 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:10.293 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:10.294 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),[1593812950278:1593812950279)
17:49:10.294 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 1 ms
17:49:10.294 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=226 in 0 ms (+sync=0 ms)
17:49:10.295 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),downstreamsRoutable=true
17:49:11.295 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:11.295 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:11.297 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),[1593812950278:1593812950279),[1593812951279:1593812951280)
17:49:11.298 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 3 ms
17:49:11.298 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=256 in 0 ms (+sync=0 ms)
17:49:11.299 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),downstreamsRoutable=true
17:49:12.282 [dataConsumerT] DEBUG u.a.i.l.s.r.OutputQueueWorker - Setting data with ts=1593812952280
17:49:12.299 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:12.300 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:12.301 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),[1593812950278:1593812950279),[1593812951279:1593812951280),[1593812952280:1593812952281)
17:49:12.302 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 3 ms
17:49:12.302 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Read routes: []
17:49:12.302 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=286 in 0 ms (+sync=0 ms)
17:49:12.303 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),downstreamsRoutable=true
17:49:12.302 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Parsing OLSRETX routes
17:49:12.303 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Checking routes against upOpIds: {-1=localhost}
17:49:12.303 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Up op costs: {}
17:49:13.303 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:13.303 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:13.303 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),[1593812950278:1593812950279),[1593812951279:1593812951280),[1593812952280:1593812952281),[1593812953281:1593812953282)
17:49:13.304 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 1 ms
17:49:13.304 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=316 in 0 ms (+sync=0 ms)
17:49:13.304 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),downstreamsRoutable=true
17:49:14.304 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:14.305 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:14.308 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),[1593812950278:1593812950279),[1593812951279:1593812951280),[1593812952280:1593812952281),[1593812953281:1593812953282),[1593812954281:1593812954282)
17:49:14.309 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 5 ms
17:49:14.309 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),downstreamsRoutable=true
17:49:14.309 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=346 in 0 ms (+sync=0 ms)
17:49:14.310 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Read routes: []
17:49:14.310 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Parsing OLSRETX routes
17:49:14.310 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Checking routes against upOpIds: {-1=localhost}
17:49:14.310 [NetRateMonitor] INFO  u.a.i.lsds.seep.manet.NetRateMonitor - Up op costs: {}
Exception in thread "idhjw-/127.0.0.1-T-0" com.esotericsoftware.kryo.KryoException: Buffer underflow.
	at com.esotericsoftware.kryo.io.Input.require(Input.java:181)
	at com.esotericsoftware.kryo.io.Input.readVarInt(Input.java:355)
	at com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:794)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:655)
	at uk.ac.imperial.lsds.seep.comm.IncomingDataHandlerWorker.run(IncomingDataHandlerWorker.java:198)
	at java.lang.Thread.run(Thread.java:748)
17:49:15.310 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op indices:[0]
17:49:15.310 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl to up op id:-1
17:49:15.311 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Writing failure ctrl, node=-1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),upOp=-1::[1593812944274:1593812944275),[1593812945274:1593812945275),[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),[1593812950278:1593812950279),[1593812951279:1593812951280),[1593812952280:1593812952281),[1593812953281:1593812953282),[1593812954281:1593812954282)
17:49:15.311 [Thread-3] DEBUG u.a.i.lsds.seep.runtimeengine.CoreRE - Wrote failure ctrl in 1 ms
17:49:15.312 [Thread-1] DEBUG u.a.i.l.s.r.ControlDispatcherWorker - Wrote control tuple ControlTuple.FAILURE_CTRL to -1,size=346 in 1 ms (+sync=1 ms)
17:49:15.312 [Thread-3] DEBUG u.a.i.l.s.reliable.FailureCtrlWriter - Writing failure ctrl: -1::[1593812946274:1593812946275),[1593812947275:1593812947276),[1593812948276:1593812948277),[1593812949277:1593812949278),downstreamsRoutable=true
